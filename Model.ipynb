{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import warnings\n",
    "from math import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [eval(l.decode('utf-8')) for l in gzip.open('assignment1/train.json.gz', 'r')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### In the task 1, I tried Jaccard Similarity and baseline model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the begining, I built a validation set of positive and negative samples to evaluate the model performance.  \n",
    "  \n",
    "In the Jaccard Similarity model, I used an item-category dictionary that restores all the categories that each item belongs to and a user-category dictionary that restores all the categories that each user has purchased. Next step is to compare the similarity between the categories that an item that belongs to and all the categories that users purchased so as to get their average similarity scores. Then based on the average similarity scores that rank in the descending order, the first half pairs are the ones that purchased. However, the accuracy I got in the validation set is 0.6103.  \n",
    "  \n",
    "In the baseline model, I also built an item-category dictionary that restores all the categories that each item belongs to and a user-purchased category dictionary that restores all the categories that each user has purchased. If the user is not in the user-purchased category dictionary or the item is not in the item-category dictionary, then I assume that in this pair, user wouldn't purchase this item. If the item is in the item-category dictionaryï¼Œthen whether the user is the purchased dictionary determine whether the user would purchase the item or not. In the baseline model, I chose lambda=5 because I tried a set of lambdas ranging from 0.01 to 100 and the accuracy in the validation set is the highest when the lambda equals to 5. And I split 2000 observations into the validation set so as to train the model better. In this way, I got the final result of 0.65 in the validation set.   \n",
    "  \n",
    "Therefore, I chose to use the baseline model for the task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d21bc33522a4525a4bb3acb2a93c70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=100000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_ = data\n",
    "np.random.shuffle(data_)\n",
    "train, val = data_[:100000], [(d['reviewerID'], d['itemID']) for d in data_[100000:]]\n",
    "userid = list(set([d['reviewerID'] for d in data_]))\n",
    "itemid = list(set([d['itemID'] for d in data_]))\n",
    "user_item = list(set([(d['reviewerID'], d['itemID']) for d in data_]))\n",
    "\n",
    "f_val = []\n",
    "for i in tqdm(range(100000)):\n",
    "    user, item = np.random.choice(userid), np.random.choice(itemid)\n",
    "    while (user, item) in user_item or (user, item) in f_val:\n",
    "        user, item = np.random.choice(userid), np.random.choice(itemid)\n",
    "    f_val.append((user, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Jaccard Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    }
   ],
   "source": [
    "user_cat, item_cat = {}, {}\n",
    "for i in train:\n",
    "    user, item, cats = i['reviewerID'], i['itemID'], i['categories'] \n",
    "    if item not in item_cat:\n",
    "        item_cat[item] = set()\n",
    "    if user not in user_cat:\n",
    "        user_cat[user] = set()\n",
    "    for c in cats:\n",
    "        for l in c:\n",
    "            item_cat[item].add(l)\n",
    "            user_cat[user].add(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15384615384615385 0\n",
      "19917\n",
      "0.6103\n"
     ]
    }
   ],
   "source": [
    "user_cat, item_cat = {}, {}\n",
    "for i in train:\n",
    "    user, item, cats = i['reviewerID'], i['itemID'], i['categories'] \n",
    "    if item not in item_cat:\n",
    "        item_cat[item] = set()\n",
    "    if user not in user_cat:\n",
    "        user_cat[user] = set()\n",
    "    for c in cats:\n",
    "        for l in c:\n",
    "            item_cat[item].add(l)\n",
    "            user_cat[user].add(l)\n",
    "\n",
    "\n",
    "def jaccard_sim(x,y):\n",
    "    intersection_cardinality = len(set.intersection(*[set(x), set(y)]))\n",
    "    union_cardinality = len(set.union(*[set(x), set(y)]))\n",
    "    return intersection_cardinality/float(union_cardinality)\n",
    "\n",
    "result, all_avg = [], []\n",
    "count = 0\n",
    "for u,i in val + f_val:\n",
    "    if i in item_cat and u in user_cat:\n",
    "        all_sim = []\n",
    "        sim = jaccard_sim(user_cat[u],item_cat[i])\n",
    "        all_sim.append(sim)\n",
    "        avg_sim = np.mean(all_sim)\n",
    "        count += avg_sim==0\n",
    "    else:\n",
    "        avg_sim = 0    \n",
    "    result.append((u,i,avg_sim))  \n",
    "    \n",
    "u, i, avg_sim = zip(*result)  \n",
    "avg_sim = sorted(list(avg_sim), reverse = True)\n",
    "median = avg_sim[len(avg_sim)//2]\n",
    "print(median, count)\n",
    "print(sum(np.array(avg_sim)==0))\n",
    "score = []\n",
    "for u,i,avg_sim in result:\n",
    "    if avg_sim >= median:\n",
    "        s = 1\n",
    "        score.append((u,i,s))\n",
    "    else:\n",
    "        s = 0\n",
    "        score.append((u,i,s))\n",
    "ur, ir, sr = zip(*score)\n",
    "\n",
    "accuracy = sum(np.array(sr) == ([1]*len(val) + [0]*len(f_val)))/len(sr)\n",
    "print(accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = open('assignment1/prediction_Purchase.txt','w')\n",
    "for l in open('assignment1/pairs_Purchase.txt','r'):\n",
    "    if l.startswith('reviewerID'):\n",
    "        pred.write(l)\n",
    "        continue\n",
    "    else:\n",
    "        u,i = l.strip().split('-')\n",
    "    if i in i_user and u in u_item:\n",
    "        all_sim = []\n",
    "        for user in i_user[i]:\n",
    "            sim = jaccard_sim(u_item[u],u_item[user])\n",
    "            all_sim.append(sim)\n",
    "            if sum(all_sim)/len(all_sim) > 0.3:\n",
    "                pred.write(u + '-' + i + \",1\\n\")\n",
    "            else:\n",
    "                pred.write(u + '-' + i + \",0\\n\")\n",
    "pred.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pur, item_cat = {}, {}\n",
    "for d in train:\n",
    "    user, item, cat = d['reviewerID'], d['itemID'], d['categories']\n",
    "    if user not in pur:\n",
    "        pur[user] = set()\n",
    "    if item not in item_cat:\n",
    "        item_cat[item] = set(map(tuple, cat))\n",
    "    for c in cat:\n",
    "        pur[user].add(tuple(c))\n",
    "\n",
    "result = []\n",
    "for u, i in val + f_val:\n",
    "    if i not in item_cat or u not in pur:\n",
    "        result.append(1)\n",
    "    else:\n",
    "        s = 0\n",
    "        for cat in item_cat[i]:\n",
    "            if cat in pur[u]:\n",
    "                s += 1\n",
    "        if s != 0:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "\n",
    "accuracy = sum(np.array(result) == ([1]*len(val) + [0]*len(f_val)))/len(result)\n",
    "print(accuracy)\n",
    "\n",
    "dat = [(d['reviewerID'], d['itemID'], d['categories']) for d in data_]\n",
    "pur, item_cat = {}, {}\n",
    "for user, item, cat in dat:\n",
    "    if user not in pur:\n",
    "        pur[user] = set()\n",
    "    if item not in item_cat:\n",
    "        item_cat[item] = set(map(tuple, cat))\n",
    "    for c in cat:\n",
    "        pur[user].add(tuple(c))\n",
    "        \n",
    "pred = open('assignment1/prediction_Purchase.txt','w')\n",
    "for l in open('assignment1/pairs_Purchase.txt','r'):\n",
    "    if l.startswith('reviewerID'):\n",
    "        pred.write(l)\n",
    "        continue\n",
    "    else:\n",
    "        u,i = l.strip().split('-')\n",
    "    if i not in item_cat or u not in pur:\n",
    "        pred.write(u + '-' + i + \",0\\n\")\n",
    "    else:\n",
    "        s = 0\n",
    "        for cat in item_cat[i]:\n",
    "            if cat in pur[u]:\n",
    "                s += 1\n",
    "        if s != 0:\n",
    "            pred.write(u + '-' + i + \",1\\n\")\n",
    "        else:\n",
    "            pred.write(u + '-' + i + \",0\\n\")\n",
    "pred.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task I tried three models. They are baseline model, y~alpha + beta_i + beta_u and the latent-factor model. It turned out that the latent-factor model worked best in this case.  \n",
    "  \n",
    "I split 2000 observations into the validation set so as to train the model better. In the model, I initialized the alpha as the average rating, and initialized beta_i, beta_u, gamma_i, gamma_u as 0 or an array of 0. Then I used gradient descent in the model to find the optimized values. If the user is in the beta_u dictionary and the item is in the beta_i dictionary, then the rating of this pair equals to alpha + beta_i[i] + beta_u[u] + sum(gamma_i[i]*gamma_u[u]). If the user is not in the beta_u dictionary, then I assume beta_u and gamma_u equal to 0. It works the same when the item is not in the beta_i dictionary.   \n",
    "  \n",
    "Here I also ran the model with different lambda and dimensions and it turns out the lambda = 5 and dimension =6 would result to a relative lower MSE in the validation set. In this way, I got the final MSE of 1.1359 in the validation set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data\n",
    "np.random.shuffle(data_)\n",
    "train = [(d['reviewerID'], d['itemID'], d['rating']) for d in data_[:-2000]]\n",
    "val = [(d['reviewerID'], d['itemID'], d['rating']) for d in data_[-2000:]]\n",
    "t_user, t_item, t_rating = zip(*train)\n",
    "v_user, u_item, u_rating = zip(*val)\n",
    "\n",
    "lr, lam, dim= 0.01, 5, 6\n",
    "mse_, mse = 30, 29\n",
    "alpha = np.mean(t_rating)\n",
    "beta_i, beta_u, gamma_i, gamma_u = {}, {}, {}, {}\n",
    "i_count, u_count = {}, {}\n",
    "for u, i, r in train:\n",
    "    if i in i_count:\n",
    "        i_count[i] += 1\n",
    "    else:\n",
    "        i_count[i] = 1\n",
    "    if u in u_count:\n",
    "        u_count[u] += 1\n",
    "    else:\n",
    "        u_count[u] = 1\n",
    "for i in i_count:\n",
    "    beta_i[i] = 0\n",
    "    gamma_i[i] = np.zeros(dim)\n",
    "for u in u_count:\n",
    "    beta_u[u] = 0\n",
    "    gamma_u[u] = np.zeros(dim)\n",
    "while mse_ - mse > 10**(-6):\n",
    "    mse_ = mse\n",
    "    d_alpha = 0\n",
    "    dbeta_i = {i:2*lam*beta_i[i] for i in i_count}\n",
    "    dbeta_u = {u:2*lam*beta_u[u] for u in u_count}\n",
    "    dgamma_i = {i:2*lam*gamma_i[i] for i in i_count}\n",
    "    dgamma_u = {u:2*lam*gamma_u[u] for u in u_count}\n",
    "    for u, i, r in train:\n",
    "        error = alpha + beta_i[i] + beta_u[u] + sum(gamma_i[i]*gamma_u[u]) - r\n",
    "        d_alpha += 2*error\n",
    "        dbeta_i[i] += 2*error\n",
    "        dbeta_u[u] += 2*error\n",
    "        dgamma_i[i] += 2*error*gamma_u[u]\n",
    "        dgamma_u[u] += 2*error*gamma_i[i]\n",
    "    alpha = alpha - (d_alpha/len(train))*lr\n",
    "    beta_i = {i:beta_i[i]-lr*dbeta_i[i]/i_count[i] for i in i_count}\n",
    "    beta_u = {u:beta_u[u]-lr*dbeta_u[u]/u_count[u] for u in u_count}\n",
    "    gamma_i = {i:gamma_i[i]-lr*dgamma_i[i]/i_count[i] for i in i_count}\n",
    "    gamma_u = {u:gamma_u[u]-lr*dgamma_u[u]/u_count[u] for u in u_count}\n",
    "    err_2 = 0\n",
    "    beta_i_mean = np.mean(list(beta_i.values()))\n",
    "    beta_u_mean = np.mean(list(beta_u.values()))\n",
    "    for u, i, r in val:\n",
    "        if u in beta_u and i in beta_i:\n",
    "            err_2 += (alpha + beta_i[i] + beta_u[u] + sum(gamma_i[i]*gamma_u[u]) - r)**2\n",
    "        elif u not in beta_u and i in beta_i:\n",
    "            err_2 += (alpha + beta_i[i] + beta_u_mean - r)**2\n",
    "        elif u in beta_u and i not in beta_i:\n",
    "            err_2 += (alpha + beta_i_mean + beta_u[u] - r)**2\n",
    "        else:\n",
    "            err_2 += (alpha + beta_i_mean + beta_u_mean - r)**2\n",
    "    mse = err_2/len(val)\n",
    "\n",
    "pred = open('assignment1/prediction_Rating.txt','w')\n",
    "for l in open('assignment1/pairs_Rating.txt','r'):\n",
    "    if l.startswith('reviewerID'):\n",
    "        pred.write(l)\n",
    "        continue\n",
    "    else:\n",
    "        u,i = l.strip().split('-')\n",
    "    if u in beta_u and i in beta_i:\n",
    "        r = alpha + beta_i[i] + beta_u[u] + sum(gamma_i[i]*gamma_u[u])\n",
    "    elif u not in beta_u and i in beta_i:\n",
    "        r = alpha + beta_i[i] + beta_u_mean\n",
    "    elif u in beta_u and i not in beta_i:\n",
    "        r = alpha + beta_i_mean + beta_u[u]\n",
    "    else:\n",
    "        r = alpha + beta_i_mean + beta_u_mean\n",
    "    pred.write(u + '-' + i + ',{}\\n'.format(r))\n",
    "pred.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
